{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Code for experiments with colored MNIST and Celeba\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Imports\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import gc\n",
                "import json\n",
                "import warnings\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from tensorboardX import SummaryWriter\n",
                "from PIL import PngImagePlugin\n",
                "\n",
                "from tqdm import tqdm_notebook as tqdm\n",
                "from IPython.display import clear_output\n",
                "\n",
                "sys.path.append(\"..\")\n",
                "from src.losses import VGGPerceptualLoss as VGGLoss\n",
                "from src.resnet2 import ResNet_D\n",
                "from src.unet import UNet\n",
                "from src.u2net import U2NET\n",
                "\n",
                "from src.tools import (\n",
                "    set_random_seed,\n",
                "    unfreeze,\n",
                "    freeze,\n",
                "    weights_init_D,\n",
                "    fig2tensor,\n",
                ")\n",
                "from src.samplers import get_paired_sampler\n",
                "from src.plotters import (\n",
                "    plot_pushed_images,\n",
                "    plot_pushed_random_paired_images,\n",
                ")\n",
                "\n",
                "\n",
                "LARGE_ENOUGH_NUMBER = 100\n",
                "PngImagePlugin.MAX_TEXT_CHUNK = LARGE_ENOUGH_NUMBER * (1024**2)\n",
                "\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "\n",
                "%matplotlib inline "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gc.collect()\n",
                "torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Config\n",
                "\n",
                "Dataset choosing in the first rows\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "parameters"
                ]
            },
            "outputs": [],
            "source": [
                "SEED = 0x3060\n",
                "set_random_seed(SEED)\n",
                "\n",
                "# dataset choosing\n",
                "# DATASET, DATASET_PATH, REVERSE = 'comic_faces_v1', '../datasets/face2comics_v1.0.0_by_Sxela', False\n",
                "DATASET, DATASET_PATH, REVERSE = \"celeba_mask\", \"../datasets/CelebAMask-HQ\", False\n",
                "# DATASET, DATASET_PATH, REVERSE = \"FS2K\", \"../datasets/FS2K/\", False\n",
                "\n",
                "IMG_SIZE = 256\n",
                "DATASET1_CHANNELS = 3\n",
                "DATASET2_CHANNELS = 3\n",
                "\n",
                "# GPU choosing\n",
                "DEVICE_IDS = [1]\n",
                "assert torch.cuda.is_available()\n",
                "torch.cuda.set_device(f\"cuda:{DEVICE_IDS[0]}\")\n",
                "\n",
                "CONTINUE = 0\n",
                "\n",
                "# All hyperparameters below is set to the values used for the experiments, which discribed in the article\n",
                "\n",
                "# training algorithm settings\n",
                "BATCH_SIZE = 2  # 1 for testing\n",
                "T_ITERS = 10\n",
                "MAX_STEPS = 30000 + 1  # 2501 for testing\n",
                "COST = \"vgg\"  #'mse' # 'mae' # 'vgg'\n",
                "\n",
                "\n",
                "# optimizer settings\n",
                "D_LR, T_LR = 1e-4, 1e-4\n",
                "T_GRADIENT_MAX_NORM = float(100)\n",
                "D_GRADIENT_MAX_NORM = float(100)\n",
                "\n",
                "# network settings\n",
                "T_TYPE = \"U2Net\"  # 'UNet' # or  ('ResNet_pix2pix' - not implemented)\n",
                "D_TYPE = (\n",
                "    \"ResNet\"  # or 'ResNet_pix2pix' - DOES NOT WORK WELL (it is actually not a resnet:)\n",
                ")\n",
                "\n",
                "D_NORM = \"none\"  # For our ResNet_D uses the \"batchnorm\" or \"none\".\n",
                "CONDITIONAL = False  # Test conditional NOT (not needed anymore)\n",
                "NOT = True  # Train Neural optimal transport or pure regression\n",
                "\n",
                "# plot settings\n",
                "GRAY_PLOTS = False\n",
                "\n",
                "# log settings\n",
                "TRACK_VAR_INTERVAL = 1000\n",
                "PLOT_INTERVAL = 500\n",
                "CPKT_INTERVAL = 5000\n",
                "\n",
                "FID_EPOCHS = 1\n",
                "\n",
                "EXP_NAME = f\"GNOT_Paired_{DATASET}_{SEED}\"\n",
                "OUTPUT_PATH = f\"../saved_models/{EXP_NAME}/\"\n",
                "\n",
                "if not os.path.exists(OUTPUT_PATH):\n",
                "    os.makedirs(OUTPUT_PATH)\n",
                "\n",
                "writer = SummaryWriter(f\"../logdir/{EXP_NAME}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config = dict(\n",
                "    SEED=SEED,\n",
                "    DATASET=DATASET,\n",
                "    T_TYPE=T_TYPE,\n",
                "    D_TYPE=D_TYPE,\n",
                "    T_ITERS=T_ITERS,\n",
                "    D_LR=D_LR,\n",
                "    T_LR=T_LR,\n",
                "    BATCH_SIZE=BATCH_SIZE,\n",
                "    CONDITIONAL=CONDITIONAL,\n",
                "    NOT=NOT,\n",
                "    COST=COST,\n",
                "    T_GRADIENT_MAX_NORM=T_GRADIENT_MAX_NORM,\n",
                "    D_GRADIENT_MAX_NORM=D_GRADIENT_MAX_NORM,\n",
                "    TRACK_VAR_INTERVAL=TRACK_VAR_INTERVAL,\n",
                "    FID_EPOCHS=FID_EPOCHS,\n",
                ")\n",
                "\n",
                "with open(os.path.join(OUTPUT_PATH, \"config.json\"), \"w\") as json_file:\n",
                "    json_str = json.dumps(config, indent=4)\n",
                "    json_file.write(json_str)\n",
                "\n",
                "log = dict(CONTINUE=CONTINUE)\n",
                "with open(os.path.join(OUTPUT_PATH, \"log.json\"), \"w\") as log_file:\n",
                "    log_str = json.dumps(log, indent=4)\n",
                "    log_file.write(log_str)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if COST == \"vgg\":\n",
                "    vgg_loss = VGGLoss().cuda()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Loading data stats for testing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# filename = \"../stats/{}_{}_{}_test.json\".format(DATASET, IMG_SIZE, REVERSE)\n",
                "# with open(filename, \"r\") as fp:\n",
                "#     data_stats = json.load(fp)\n",
                "#     mu_data, sigma_data = data_stats[\"mu\"], data_stats[\"sigma\"]\n",
                "# del data_stats"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Initialize samplers\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "XY_sampler, XY_test_sampler = get_paired_sampler(\n",
                "    DATASET,\n",
                "    DATASET_PATH,\n",
                "    img_size=IMG_SIZE,\n",
                "    reverse=REVERSE,\n",
                "    num_workers=12,\n",
                ")\n",
                "# XY_sampler, XY_test_sampler = get_paired_sampler(\n",
                "#     DATASET, DATASET_PATH, img_size=IMG_SIZE, reverse=REVERSE, num_workers=8, device='cuda'\n",
                "# )\n",
                "\n",
                "torch.cuda.empty_cache()\n",
                "gc.collect()\n",
                "clear_output()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Models initialization\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if D_TYPE == \"ResNet\":\n",
                "    D = ResNet_D(\n",
                "        IMG_SIZE,\n",
                "        nc=3 if not CONDITIONAL else 6,\n",
                "        bn=D_NORM != \"none\",\n",
                "    ).cuda()\n",
                "    D.apply(weights_init_D)\n",
                "else:\n",
                "    raise NotImplementedError(\"Unknown D_TYPE: {}\".format(D_TYPE))\n",
                "\n",
                "if T_TYPE == \"UNet\":\n",
                "    T = UNet(DATASET1_CHANNELS, DATASET2_CHANNELS, base_factor=48).cuda()\n",
                "elif T_TYPE == \"U2Net\":\n",
                "    T = U2NET(in_ch=DATASET1_CHANNELS, out_ch=DATASET2_CHANNELS).cuda()\n",
                "else:\n",
                "    raise NotImplementedError(\"Unknown T_TYPE: {}\".format(T_TYPE))\n",
                "\n",
                "if len(DEVICE_IDS) > 1:\n",
                "    T = nn.DataParallel(T, device_ids=DEVICE_IDS)\n",
                "    D = nn.DataParallel(D, device_ids=DEVICE_IDS)\n",
                "\n",
                "print(\"T params:\", np.sum([np.prod(p.shape) for p in T.parameters()]))\n",
                "print(\"D params:\", np.sum([np.prod(p.shape) for p in D.parameters()]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "T_opt = torch.optim.Adam(T.parameters(), lr=T_LR, weight_decay=1e-10)\n",
                "D_opt = torch.optim.Adam(D.parameters(), lr=D_LR, weight_decay=1e-10)\n",
                "\n",
                "T_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
                "    T_opt, milestones=[15000, 30000, 45000, 70000], gamma=0.5\n",
                ")\n",
                "D_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
                "    D_opt, milestones=[15000, 30000, 45000, 70000], gamma=0.5\n",
                ")\n",
                "\n",
                "if CONTINUE > 0:\n",
                "    T_opt.load_state_dict(\n",
                "        torch.load(os.path.join(OUTPUT_PATH, f\"T_opt_{SEED}_{CONTINUE}.pt\"))\n",
                "    )\n",
                "    T_scheduler.load_state_dict(\n",
                "        torch.load(os.path.join(OUTPUT_PATH, f\"T_scheduler_{SEED}_{CONTINUE}.pt\"))\n",
                "    )\n",
                "\n",
                "    T.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f\"T_{SEED}_{CONTINUE}.pt\")))\n",
                "    D.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f\"D_{SEED}_{CONTINUE}.pt\")))\n",
                "\n",
                "    if len(DEVICE_IDS) > 1:\n",
                "        T = nn.DataParallel(T, device_ids=DEVICE_IDS)\n",
                "        D = nn.DataParallel(D, device_ids=DEVICE_IDS)\n",
                "\n",
                "    D_opt.load_state_dict(\n",
                "        torch.load(os.path.join(OUTPUT_PATH, f\"D_opt_{SEED}_{CONTINUE}.pt\"))\n",
                "    )\n",
                "    D_scheduler.load_state_dict(\n",
                "        torch.load(os.path.join(OUTPUT_PATH, f\"D_scheduler_{SEED}_{CONTINUE}.pt\"))\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_fixed, Y_fixed = XY_sampler.sample(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_test_fixed, Y_test_fixed = XY_test_sampler.sample(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Plots Test\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plot_pushed_images(X_fixed, Y_fixed, T)\n",
                "fig, axes = plot_pushed_random_paired_images(XY_sampler, T)\n",
                "fig, axes = plot_pushed_images(X_test_fixed, Y_test_fixed, T)\n",
                "fig, axes = plot_pushed_random_paired_images(XY_test_sampler, T)\n",
                "writer.add_image(\"pushed random paired images\", fig2tensor(fig))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Main training cycle and logging\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "progress_bar = tqdm(total=MAX_STEPS, initial=CONTINUE)\n",
                "\n",
                "for step in range(MAX_STEPS):\n",
                "    if step < CONTINUE:\n",
                "        continue\n",
                "\n",
                "    # T optimization\n",
                "    unfreeze(T)\n",
                "    freeze(D)\n",
                "\n",
                "    for t_iter in range(T_ITERS):\n",
                "        T_opt.zero_grad()\n",
                "        X, Y = XY_sampler.sample(BATCH_SIZE)\n",
                "        T_X = T(X)\n",
                "\n",
                "        if CONDITIONAL:\n",
                "            T_X = torch.cat([T_X, X], dim=1)\n",
                "\n",
                "        if COST == \"rmse\":\n",
                "            T_loss = (Y - T_X[:, :3]).flatten(start_dim=1).norm(dim=1).mean()\n",
                "        elif COST == \"mse\":\n",
                "            T_loss = (Y - T_X[:, :3]).flatten(start_dim=1).square().sum(dim=1).mean()\n",
                "        elif COST == \"mae\":\n",
                "            T_loss = (Y - T_X[:, :3]).flatten(start_dim=1).abs().sum(dim=1).mean()\n",
                "        elif COST == \"vgg\":\n",
                "            T_loss = vgg_loss(Y, T_X[:, :3]).mean()\n",
                "        else:\n",
                "            raise Exception(\"Unknown COST\")\n",
                "\n",
                "        if NOT:\n",
                "            T_loss -= D(T_X).mean()\n",
                "\n",
                "        writer.add_scalar(\"T_loss\", T_loss.item(), step)\n",
                "\n",
                "        T_loss.backward()\n",
                "        T_opt.step()\n",
                "    T_scheduler.step()\n",
                "    del T_loss, T_X, X, Y\n",
                "    gc.collect()\n",
                "    torch.cuda.empty_cache()\n",
                "\n",
                "    if NOT:\n",
                "        # D optimization\n",
                "        freeze(T)\n",
                "        unfreeze(D)\n",
                "        X, _ = XY_sampler.sample(BATCH_SIZE)\n",
                "        with torch.no_grad():\n",
                "            T_X = T(X)\n",
                "        _, Y = XY_sampler.sample(BATCH_SIZE)  # We may use the previous batch here\n",
                "        if CONDITIONAL:\n",
                "            with torch.no_grad():\n",
                "                T_X = torch.cat([T_X, X], dim=1)\n",
                "                Y = torch.cat([Y, X], dim=1)\n",
                "        D_opt.zero_grad()\n",
                "        D_loss = D(T_X).mean() - D(Y).mean()\n",
                "        writer.add_scalar(\"D_loss\", D_loss.item(), step)\n",
                "        D_loss.backward()\n",
                "        D_opt.step()\n",
                "        D_scheduler.step()\n",
                "        del D_loss, Y, X, T_X, _\n",
                "        gc.collect()\n",
                "        torch.cuda.empty_cache()\n",
                "\n",
                "    progress_bar.update(1)\n",
                "\n",
                "    if step % PLOT_INTERVAL == 0:\n",
                "        progress_bar.close()\n",
                "        clear_output(wait=True)\n",
                "        progress_bar = tqdm(total=MAX_STEPS, initial=CONTINUE)\n",
                "        print(\"Plotting\")\n",
                "\n",
                "        inference_T = T\n",
                "        inference_T.eval()\n",
                "\n",
                "        print(\"Fixed Test Images\")\n",
                "        fig, axes = plot_pushed_images(\n",
                "            X_test_fixed, Y_test_fixed, inference_T, gray=GRAY_PLOTS\n",
                "        )\n",
                "        plt.show(fig)\n",
                "        plt.close(fig)\n",
                "\n",
                "        print(\"Random Test Images\")\n",
                "        fig, axes = plot_pushed_random_paired_images(\n",
                "            XY_test_sampler, inference_T, gray=GRAY_PLOTS\n",
                "        )\n",
                "        plt.show(fig)\n",
                "        plt.close(fig)\n",
                "\n",
                "    if step != 0 and step % CPKT_INTERVAL == 0:\n",
                "        freeze(T)\n",
                "        if len(DEVICE_IDS) > 1:\n",
                "            torch.save(\n",
                "                T.module.state_dict(), os.path.join(OUTPUT_PATH, f\"T_{SEED}_{step}.pt\")\n",
                "            )\n",
                "            torch.save(\n",
                "                D.module.state_dict(), os.path.join(OUTPUT_PATH, f\"D_{SEED}_{step}.pt\")\n",
                "            )\n",
                "        else:\n",
                "            torch.save(T.state_dict(), os.path.join(OUTPUT_PATH, f\"T_{SEED}_{step}.pt\"))\n",
                "            torch.save(D.state_dict(), os.path.join(OUTPUT_PATH, f\"D_{SEED}_{step}.pt\"))\n",
                "\n",
                "        torch.save(\n",
                "            D_opt.state_dict(), os.path.join(OUTPUT_PATH, f\"D_opt_{SEED}_{step}.pt\")\n",
                "        )\n",
                "        torch.save(\n",
                "            T_opt.state_dict(), os.path.join(OUTPUT_PATH, f\"T_opt_{SEED}_{step}.pt\")\n",
                "        )\n",
                "        torch.save(\n",
                "            D_scheduler.state_dict(),\n",
                "            os.path.join(OUTPUT_PATH, f\"D_scheduler_{SEED}_{step}.pt\"),\n",
                "        )\n",
                "        torch.save(\n",
                "            T_scheduler.state_dict(),\n",
                "            os.path.join(OUTPUT_PATH, f\"T_scheduler_{SEED}_{step}.pt\"),\n",
                "        )\n",
                "\n",
                "        log[\"CONTINUE\"] = CONTINUE\n",
                "        with open(os.path.join(OUTPUT_PATH, \"log.json\"), \"w\") as log_file:\n",
                "            log_str = json.dumps(log, indent=4)\n",
                "            log_file.write(log_str)\n",
                "\n",
                "    if step % TRACK_VAR_INTERVAL == 0:\n",
                "        pass\n",
                "        # print(\"Computing FID\")\n",
                "        # mu, sigma = get_pushed_loader_stats(\n",
                "        #     T,\n",
                "        #     XY_test_sampler.loader,\n",
                "        #     n_epochs=FID_EPOCHS,\n",
                "        #     batch_size=BATCH_SIZE,\n",
                "        #     verbose=True,\n",
                "        # )\n",
                "        # fid = calculate_frechet_distance(mu_data, sigma_data, mu, sigma)\n",
                "        # print(f\"FID={fid}\")\n",
                "        # writer.add_scalar(\"Metrics/FID\", fid, step)\n",
                "        # del mu, sigma\n",
                "\n",
                "        # print(\"Computing LPIPS(vgg) LPIPS(alex) L1 MSE\")\n",
                "        # metrics = get_pushed_loader_metrics(\n",
                "        #     T,\n",
                "        #     XY_test_sampler.loader,\n",
                "        #     n_epochs=FID_EPOCHS,\n",
                "        #     batch_size=BATCH_SIZE,\n",
                "        #     verbose=True,\n",
                "        #     metrics=[\"mse\", \"l1\"]\n",
                "        # )\n",
                "        # print(f\"metrics={metrics}\")\n",
                "        # writer.add_scalar(\"Metrics/LPIPS(VGG)\", metrics[\"vgg\"], step)\n",
                "        # writer.add_scalar(\"Metrics/LPIPS(Alex)\", metrics[\"alex\"], step)\n",
                "        # writer.add_scalar(\"Metrics/L1\", metrics[\"l1\"], step)\n",
                "        # writer.add_scalar(\"Metrics/MSE\", metrics[\"mse\"], step)\n",
                "\n",
                "    gc.collect()\n",
                "    torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Clear resources\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    writer.close()\n",
                "    progress_bar.close()\n",
                "except Exception as e:\n",
                "    print(e)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "celltoolbar": "Tags",
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
