{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Imports\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import gc\n",
                "import warnings\n",
                "\n",
                "import torch\n",
                "import torchvision\n",
                "import numpy as np\n",
                "from torchvision.transforms import Compose, ToTensor, Resize, Normalize, Lambda\n",
                "from PIL import PngImagePlugin\n",
                "\n",
                "from IPython.display import clear_output\n",
                "\n",
                "sys.path.append(\"..\")\n",
                "from src.cunet import CUNet\n",
                "from src.enot import SDE\n",
                "from src.unet import UNet\n",
                "from src.mnistm_utils import MNISTM\n",
                "from src.tools import (\n",
                "    set_random_seed,\n",
                ")\n",
                "from src.plotters import (\n",
                "    plot_pushed_images,\n",
                "    plot_pushed_random_class_images,\n",
                "    plot_sde_pushed_images,\n",
                "    plot_sde_pushed_random_class_images,\n",
                "    plot_linked_pushed_images,\n",
                "    plot_linked_pushed_random_class_images,\n",
                "    plot_linked_sde_pushed_images,\n",
                "    plot_linked_sde_pushed_random_class_images,\n",
                ")\n",
                "from src.samplers import (\n",
                "    SubsetGuidedSampler,\n",
                "    SubsetGuidedDataset,\n",
                "    get_indicies_subset,\n",
                ")\n",
                "\n",
                "\n",
                "LARGE_ENOUGH_NUMBER = 100\n",
                "PngImagePlugin.MAX_TEXT_CHUNK = LARGE_ENOUGH_NUMBER * (1024**2)\n",
                "\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "\n",
                "%matplotlib inline "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gc.collect()\n",
                "torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## General Config"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "SEED = 0x0000\n",
                "set_random_seed(SEED)\n",
                "\n",
                "# dataset choosing\n",
                "DATASET, DATASET_PATH = \"fmnist2mnist\", \"../datasets/\"\n",
                "# DATASET, DATASET_PATH = \"mnist2mnistm\", \"../datasets/\"\n",
                "# DATASET, DATASET_PATH = \"mnist2usps\", \"../datasets/\"\n",
                "# DATASET, DATASET_PATH = \"mnist2kmnist\", \"../datasets/\"\n",
                "\n",
                "IMG_SIZE = 32\n",
                "DATASET1_CHANNELS = 1\n",
                "DATASET2_CHANNELS = 1\n",
                "\n",
                "# GPU choosing\n",
                "DEVICE_IDS = [1]\n",
                "assert torch.cuda.is_available()\n",
                "torch.cuda.set_device(f\"cuda:{DEVICE_IDS[0]}\")\n",
                "\n",
                "# training algorithm settings\n",
                "BATCH_SIZE = 32\n",
                "SUBSET_SIZE = 2\n",
                "SUBSET_CLASS = 3\n",
                "\n",
                "# plot settings\n",
                "GRAY_PLOTS = True\n",
                "\n",
                "FID_EPOCHS = 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "source_subset = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
                "new_labels_source = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\n",
                "target_subset = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
                "new_labels_target = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\n",
                "\n",
                "SUBSET_WEIGHT = [0 for _ in range(len(source_subset))]\n",
                "SUBSET_WEIGHT[SUBSET_CLASS] = 1.0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "source_transform = Compose(\n",
                "    [\n",
                "        Resize((IMG_SIZE, IMG_SIZE)),\n",
                "        ToTensor(),\n",
                "        Normalize((0.5), (0.5)),\n",
                "    ]\n",
                ")\n",
                "target_transform = source_transform\n",
                "\n",
                "if DATASET == \"mnist2kmnist\":\n",
                "    source = torchvision.datasets.MNIST\n",
                "    target = torchvision.datasets.KMNIST\n",
                "\n",
                "\n",
                "elif DATASET == \"fmnist2mnist\":\n",
                "    source = torchvision.datasets.FashionMNIST\n",
                "    target = torchvision.datasets.MNIST\n",
                "\n",
                "\n",
                "elif DATASET == \"mnist2usps\":\n",
                "    source = torchvision.datasets.MNIST\n",
                "    target = torchvision.datasets.USPS\n",
                "\n",
                "\n",
                "elif DATASET == \"mnist2mnistm\":\n",
                "    DATASET1_CHANNELS = 3\n",
                "    DATASET2_CHANNELS = 3\n",
                "\n",
                "    GRAY_PLOTS = False\n",
                "    source = torchvision.datasets.MNIST\n",
                "    target = MNISTM\n",
                "    source_transform = Compose(\n",
                "        [\n",
                "            Resize((IMG_SIZE, IMG_SIZE)),\n",
                "            ToTensor(),\n",
                "            Normalize((0.5), (0.5)),\n",
                "            Lambda(lambda x: -x.repeat(3, 1, 1)),\n",
                "        ]\n",
                "    )\n",
                "    target_transform = Compose(\n",
                "        [Resize(IMG_SIZE), ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Initialize samplers\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "source_test = source(\n",
                "    root=DATASET_PATH, train=False, download=True, transform=source_transform\n",
                ")\n",
                "source_subset_samples, source_labels, source_class_indicies = get_indicies_subset(\n",
                "    source_test,\n",
                "    new_labels=new_labels_source,\n",
                "    classes=len(source_subset),\n",
                "    subset_classes=source_subset,\n",
                ")\n",
                "source_test = torch.utils.data.TensorDataset(\n",
                "    torch.stack(source_subset_samples), torch.LongTensor(source_labels)\n",
                ")\n",
                "\n",
                "\n",
                "target_test = target(\n",
                "    root=DATASET_PATH, train=False, download=True, transform=target_transform\n",
                ")\n",
                "target_subset_samples, target_labels, target_class_indicies = get_indicies_subset(\n",
                "    target_test,\n",
                "    new_labels=new_labels_target,\n",
                "    classes=len(target_subset),\n",
                "    subset_classes=target_subset,\n",
                ")\n",
                "target_test = torch.utils.data.TensorDataset(\n",
                "    torch.stack(target_subset_samples), torch.LongTensor(target_labels)\n",
                ")\n",
                "\n",
                "full_set_test = SubsetGuidedDataset(\n",
                "    source_test,\n",
                "    target_test,\n",
                "    num_labeled=\"all\",\n",
                "    in_indicies=source_class_indicies,\n",
                "    out_indicies=target_class_indicies,\n",
                ")\n",
                "\n",
                "XY_test_sampler = SubsetGuidedSampler(full_set_test, subsetsize=1, weight=SUBSET_WEIGHT)\n",
                "\n",
                "# for accuracy\n",
                "X_test_loader = torch.utils.data.DataLoader(\n",
                "    source_test,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    shuffle=False,\n",
                "    num_workers=8,\n",
                "    # pin_memory=True,\n",
                ")\n",
                "Y_test_loader = torch.utils.data.DataLoader(\n",
                "    target_test,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    shuffle=False,\n",
                "    num_workers=8,\n",
                "    # pin_memory=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "torch.cuda.empty_cache()\n",
                "gc.collect()\n",
                "clear_output()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_test_fixed, Y_test_fixed = XY_test_sampler.sample(10)\n",
                "X_test_fixed, Y_test_fixed = X_test_fixed.flatten(0, 1), Y_test_fixed.flatten(0, 1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## GNOT"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "EXP_NAME = f\"GNOT_Unpair_{DATASET}_{SEED}\"\n",
                "LOAD_PATH = f\"../saved_models/{EXP_NAME}/\"\n",
                "\n",
                "if not os.path.exists(LOAD_PATH):\n",
                "    raise FileNotFoundError(\"no such file or directory...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### init model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "T = UNet(DATASET1_CHANNELS, DATASET2_CHANNELS, base_factor=48).cuda()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### load weights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Loading weights\")\n",
                "\n",
                "w_path = os.path.join(LOAD_PATH, \"T_10000_no_z.pt\")  # user setting\n",
                "\n",
                "T.load_state_dict(torch.load(w_path))\n",
                "print(f\"{w_path}, loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### plot"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plot_pushed_images(\n",
                "    X_test_fixed,\n",
                "    Y_test_fixed,\n",
                "    T,\n",
                "    gray=GRAY_PLOTS,\n",
                "    savefig=True,\n",
                "    save_path=\"./figs/Unpair/GNOT/fix\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plot_pushed_random_class_images(\n",
                "    XY_test_sampler,\n",
                "    T,\n",
                "    plot_n_samples=10,\n",
                "    gray=GRAY_PLOTS,\n",
                "    savefig=True,\n",
                "    save_path=\"./figs/Unpair/GNOT/random\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ENOT"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SDE network settings\n",
                "EPSILON = 0  # [0 , 1, 10]\n",
                "IMAGE_INPUT = True\n",
                "PREDICT_SHIFT = True\n",
                "N_STEPS = 5  #\n",
                "UNET_BASE_FACTOR = 128\n",
                "TIME_DIM = 128\n",
                "USE_POSITIONAL_ENCODING = True\n",
                "ONE_STEP_INIT_ITERS = 0\n",
                "USE_GRADIENT_CHECKPOINT = False\n",
                "N_LAST_STEPS_WITHOUT_NOISE = 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "EXP_NAME = f\"ENOT_Unpair_{DATASET}_{SEED}\"\n",
                "LOAD_PATH = f\"../saved_models/{EXP_NAME}/\"\n",
                "\n",
                "if not os.path.exists(LOAD_PATH):\n",
                "    raise FileNotFoundError(\"no such file or directory...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### init model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "T = CUNet(\n",
                "    DATASET1_CHANNELS, DATASET2_CHANNELS, TIME_DIM, base_factor=UNET_BASE_FACTOR\n",
                ").cuda()\n",
                "\n",
                "sde = SDE(\n",
                "    shift_model=T,\n",
                "    epsilon=EPSILON,\n",
                "    n_steps=N_STEPS,\n",
                "    time_dim=TIME_DIM,\n",
                "    n_last_steps_without_noise=N_LAST_STEPS_WITHOUT_NOISE,\n",
                "    use_positional_encoding=USE_POSITIONAL_ENCODING,\n",
                "    use_gradient_checkpoint=USE_GRADIENT_CHECKPOINT,\n",
                "    predict_shift=PREDICT_SHIFT,\n",
                "    image_input=IMAGE_INPUT,\n",
                ").cuda()\n",
                "\n",
                "print(\"sde params:\", np.sum([np.prod(p.shape) for p in sde.parameters()]))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Load weights\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Loading weights\")\n",
                "\n",
                "w_path = os.path.join(LOAD_PATH, f\"T_{SEED}_5000.pt\")  # user setting\n",
                "\n",
                "sde.load_state_dict(torch.load(w_path))\n",
                "\n",
                "print(f\"{w_path}, loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### plot"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plot_sde_pushed_images(\n",
                "    X_test_fixed,\n",
                "    Y_test_fixed,\n",
                "    sde,\n",
                "    gray=GRAY_PLOTS,\n",
                "    plot_trajectory=False,\n",
                "    savefig=True,\n",
                "    save_path=\"./figs/Unpair/ENOT/fix\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plot_sde_pushed_random_class_images(\n",
                "    XY_test_sampler,\n",
                "    sde,\n",
                "    plot_n_samples=10,\n",
                "    gray=GRAY_PLOTS,\n",
                "    plot_trajectory=False,\n",
                "    savefig=True,\n",
                "    save_path=\"./figs/Unpair/ENOT/random\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## DNOT"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# the step number adding noise in diffusion process\n",
                "DIFFUSION_STEPS = 1000\n",
                "PIVOTAL_LIST = [20, 50, 100]  # [0, 100] for testing,  [0, 20, 50, 100]\n",
                "# training algorithm settings\n",
                "STRATEGY = \"Adapt\"  # 'Fix' or 'Adapt'\n",
                "# model settings\n",
                "UNET_BASE_FACTOR = 48"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "EXP_NAME = f\"DNOT_Class_{DATASET}_{STRATEGY}_{SEED}\"\n",
                "LOAD_PATH = f\"../saved_models/{EXP_NAME}/\"\n",
                "\n",
                "if not os.path.exists(LOAD_PATH):\n",
                "    raise FileNotFoundError(\"no such file or directory...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### init model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Ts = []\n",
                "\n",
                "for i in range(len(PIVOTAL_LIST) * 2):\n",
                "    T = UNet(DATASET1_CHANNELS, DATASET2_CHANNELS, base_factor=UNET_BASE_FACTOR).cuda()\n",
                "    Ts.append(T)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### load weights\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Loading weights\")\n",
                "\n",
                "CKPT_DIR = os.path.join(LOAD_PATH, f\"iter{2000}\")  # user setting\n",
                "for i, T in enumerate(Ts):\n",
                "    w_path = os.path.join(CKPT_DIR, f\"T{i}_{SEED}.pt\")\n",
                "    T.load_state_dict(torch.load(w_path))\n",
                "    print(f\"{w_path}, loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### plot"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plot_linked_pushed_images(\n",
                "    X_test_fixed,\n",
                "    Y_test_fixed,\n",
                "    Ts,\n",
                "    gray=GRAY_PLOTS,\n",
                "    plot_trajectory=False,\n",
                "    savefig=True,\n",
                "    save_path=\"./figs/Unpair/DNOT/fix\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plot_linked_pushed_random_class_images(\n",
                "    XY_test_sampler,\n",
                "    Ts,\n",
                "    plot_n_samples=10,\n",
                "    gray=GRAY_PLOTS,\n",
                "    plot_trajectory=False,\n",
                "    savefig=True,\n",
                "    save_path=\"./figs/Unpair/DNOT/random\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## DENOT"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# the step number adding noise in diffusion process\n",
                "DIFFUSION_STEPS = 1000\n",
                "PIVOTAL_LIST = [20, 50, 100]  # [0, 100] for testing,  [0, 20, 50, 100]\n",
                "# training algorithm settings\n",
                "STRATEGY = \"Fix\"  # 'Fix' or 'Adapt'\n",
                "# SDE network settings\n",
                "EPSILON = 0  # [0 , 1, 10]\n",
                "IMAGE_INPUT = True\n",
                "PREDICT_SHIFT = True\n",
                "N_STEPS = 5  # num of shifts time\n",
                "UNET_BASE_FACTOR = 128\n",
                "TIME_DIM = 128\n",
                "USE_POSITIONAL_ENCODING = True\n",
                "ONE_STEP_INIT_ITERS = 0\n",
                "USE_GRADIENT_CHECKPOINT = False\n",
                "N_LAST_STEPS_WITHOUT_NOISE = 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "EXP_NAME = f\"DENOT_Class_{DATASET}_{STRATEGY}_{SEED}\"\n",
                "LOAD_PATH = f\"../saved_models/{EXP_NAME}/\"\n",
                "\n",
                "if not os.path.exists(LOAD_PATH):\n",
                "    raise FileNotFoundError(\"no such file or directory...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### init model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "SDEs = []\n",
                "\n",
                "for i in range(len(PIVOTAL_LIST) * 2):\n",
                "    T = CUNet(\n",
                "        DATASET1_CHANNELS, DATASET2_CHANNELS, TIME_DIM, base_factor=UNET_BASE_FACTOR\n",
                "    ).cuda()\n",
                "\n",
                "    T = SDE(\n",
                "        shift_model=T,\n",
                "        epsilon=EPSILON,\n",
                "        n_steps=N_STEPS,\n",
                "        time_dim=TIME_DIM,\n",
                "        n_last_steps_without_noise=N_LAST_STEPS_WITHOUT_NOISE,\n",
                "        use_positional_encoding=USE_POSITIONAL_ENCODING,\n",
                "        use_gradient_checkpoint=USE_GRADIENT_CHECKPOINT,\n",
                "        predict_shift=PREDICT_SHIFT,\n",
                "        image_input=IMAGE_INPUT,\n",
                "    ).cuda()\n",
                "    SDEs.append(T)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### load weights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Loading weights\")\n",
                "\n",
                "CKPT_DIR = os.path.join(LOAD_PATH, f\"iter{10000}/\")  # user setting\n",
                "for i, T in enumerate(SDEs):\n",
                "    T.load_state_dict(torch.load(os.path.join(CKPT_DIR, f\"T{i}_{SEED}.pt\")))\n",
                "    print(f\"{CKPT_DIR}/T{i}_{SEED}.pt, loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### plot"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plot_linked_sde_pushed_images(\n",
                "    X_test_fixed,\n",
                "    Y_test_fixed,\n",
                "    SDEs,\n",
                "    gray=GRAY_PLOTS,\n",
                "    plot_trajectory=False,\n",
                "    savefig=True,\n",
                "    save_path=\"./figs/Unpair/DENOT/fix\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plot_linked_sde_pushed_random_class_images(\n",
                "    XY_test_sampler,\n",
                "    SDEs,\n",
                "    plot_n_samples=10,\n",
                "    gray=GRAY_PLOTS,\n",
                "    plot_trajectory=False,\n",
                "    savefig=True,\n",
                "    save_path=\"./figs/Unpair/DENOT/random\",\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}