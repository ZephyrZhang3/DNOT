{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Toy Experiments"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import json\n",
                "import math\n",
                "import warnings\n",
                "\n",
                "import torch\n",
                "import numpy as np\n",
                "from torch.optim import Adam\n",
                "\n",
                "from tensorboardX import SummaryWriter\n",
                "from PIL import PngImagePlugin\n",
                "from matplotlib import pyplot as plt\n",
                "\n",
                "from tqdm import tqdm\n",
                "from IPython.display import clear_output\n",
                "\n",
                "sys.path.append(\"..\")\n",
                "from src import samplers\n",
                "from src.enot import integrate, make_net\n",
                "\n",
                "from src.tools import sde_push, set_random_seed, unfreeze, freeze, fig2tensor\n",
                "\n",
                "LARGE_ENOUGH_NUMBER = 100\n",
                "PngImagePlugin.MAX_TEXT_CHUNK = LARGE_ENOUGH_NUMBER * (1024**2)\n",
                "\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Config"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "SEED = 0x3060\n",
                "set_random_seed(SEED)\n",
                "\n",
                "# dataset choosing\n",
                "# DATASET, REVERSE = 'moons2swissroll2d', False\n",
                "DATASET, REVERSE = \"swissroll3d2mobius\", False\n",
                "# GPU choosing\n",
                "DEVICE_IDS = [0]\n",
                "assert torch.cuda.is_available()\n",
                "\n",
                "\n",
                "# All hyperparameters below is set to the values used for the experiments, which discribed in the article\n",
                "\n",
                "# training algorithm settings\n",
                "BATCH_SIZE = 512  # 1 for testing\n",
                "T_ITERS = 10\n",
                "MAX_STEPS = 2500 + 1  # 2501 for testing\n",
                "EPSILON_SCHEDULER_LAST_ITER = 20000\n",
                "\n",
                "# optimizer settings\n",
                "D_LR, T_LR = 1e-4, 1e-4\n",
                "BETA_D, BETA_T = 0.9, 0.9\n",
                "T_GRADIENT_MAX_NORM = float(500)\n",
                "D_GRADIENT_MAX_NORM = float(500)\n",
                "\n",
                "# SDE network settings\n",
                "EPSILON = 0  # [0 , 1, 10]\n",
                "IMAGE_INPUT = False\n",
                "PREDICT_SHIFT = True\n",
                "N_STEPS = 10\n",
                "UNET_BASE_FACTOR = 128\n",
                "TIME_DIM = 1\n",
                "USE_POSITIONAL_ENCODING = True\n",
                "ONE_STEP_INIT_ITERS = 0\n",
                "USE_GRADIENT_CHECKPOINT = False\n",
                "N_LAST_STEPS_WITHOUT_NOISE = 1\n",
                "\n",
                "# plot settings\n",
                "PLOT_N_POINTS = 10240\n",
                "\n",
                "# log settings\n",
                "LOG_INTERVAL = 500\n",
                "\n",
                "EXP_NAME = f\"ENOT_Toy_{DATASET}_{SEED}\"\n",
                "OUTPUT_PATH = f\"../saved_models/{EXP_NAME}/\"\n",
                "\n",
                "if not os.path.exists(OUTPUT_PATH):\n",
                "    os.makedirs(OUTPUT_PATH)\n",
                "\n",
                "writer = SummaryWriter(f\"../logdir/{EXP_NAME}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config = dict(\n",
                "    SEED=SEED,\n",
                "    DATASET=DATASET,\n",
                "    T_ITERS=T_ITERS,\n",
                "    D_LR=D_LR,\n",
                "    T_LR=T_LR,\n",
                "    BATCH_SIZE=BATCH_SIZE,\n",
                "    UNET_BASE_FACTOR=UNET_BASE_FACTOR,\n",
                "    N_STEPS=N_STEPS,\n",
                "    EPSILON=EPSILON,\n",
                "    USE_POSITIONAL_ENCODING=USE_POSITIONAL_ENCODING,\n",
                "    TIME_DIM=TIME_DIM,\n",
                "    ONE_STEP_INIT_ITERS=ONE_STEP_INIT_ITERS,\n",
                "    T_GRADIENT_MAX_NORM=T_GRADIENT_MAX_NORM,\n",
                "    D_GRADIENT_MAX_NORM=D_GRADIENT_MAX_NORM,\n",
                "    PREDICT_SHIFT=PREDICT_SHIFT,\n",
                "    USE_GRADIENT_CHECKPOINT=USE_GRADIENT_CHECKPOINT,\n",
                "    N_LAST_STEPS_WITHOUT_NOISE=N_LAST_STEPS_WITHOUT_NOISE,\n",
                "    EPSILON_SCHEDULER_LAST_ITER=EPSILON_SCHEDULER_LAST_ITER,\n",
                ")\n",
                "\n",
                "with open(os.path.join(OUTPUT_PATH, \"config.json\"), \"w\") as json_file:\n",
                "    json_str = json.dumps(config, indent=4)\n",
                "    json_file.write(json_str)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Initial samplers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if DATASET == \"swissroll3d2mobius\":\n",
                "    DIM = 3\n",
                "    INTEGRAL_SCALE = 1 / DIM\n",
                "    X_sampler = samplers.SwissRollSampler(dim=DIM, noise=0.5)\n",
                "    Y_sampler = samplers.MobiusStripSampler()\n",
                "elif DATASET == \"moons2swissroll2d\":\n",
                "    DIM = 2\n",
                "    INTEGRAL_SCALE = 1 / DIM\n",
                "    Y_sampler = samplers.SwissRollSampler(dim=DIM, noise=0.5)\n",
                "    X_sampler = samplers.DoubleMoonSampler()\n",
                "else:\n",
                "    raise Exception(\"DATASET error\")\n",
                "\n",
                "if REVERSE:\n",
                "    X_sampler, Y_sampler = Y_sampler, X_sampler"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### models initialization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SDE(torch.nn.Module):\n",
                "    def __init__(self, shift_model, epsilon, n_steps):\n",
                "        super().__init__()\n",
                "        self.shift_model = shift_model\n",
                "        self.noise_std = math.sqrt(epsilon)\n",
                "        self.n_steps = n_steps\n",
                "        self.delta_t = 1 / n_steps\n",
                "\n",
                "    def forward(self, x0):\n",
                "        t0 = 0\n",
                "        trajectory = [x0]\n",
                "        times = [t0]\n",
                "        shifts = []\n",
                "\n",
                "        x, t = x0, t0\n",
                "\n",
                "        for step in range(self.n_steps):\n",
                "            x, t, shift = self._step(x, t)\n",
                "\n",
                "            trajectory.append(x)\n",
                "            times.append(t)\n",
                "            shifts.append(shift)\n",
                "\n",
                "        return (\n",
                "            torch.stack(trajectory, dim=1),\n",
                "            torch.tensor(times),\n",
                "            torch.stack(shifts, dim=1),\n",
                "        )\n",
                "\n",
                "    def _step(self, x, t):\n",
                "        shift = self._get_shift(x, t)\n",
                "        noise = self._sample_noise(x)\n",
                "        return x + self.delta_t * shift + noise, t + self.delta_t, shift\n",
                "\n",
                "    def _get_shift(self, x, t):\n",
                "        batch_size = x.shape[0]\n",
                "\n",
                "        t = torch.tensor(t).repeat(batch_size).to(device=x.device)\n",
                "        inp = torch.cat((x, t[:, None]), dim=-1)\n",
                "        return self.shift_model(inp)\n",
                "\n",
                "    def _sample_noise(self, x):\n",
                "        return (\n",
                "            self.noise_std\n",
                "            * math.sqrt(self.delta_t)\n",
                "            * (torch.randn(x.shape, device=x.device))\n",
                "        )\n",
                "\n",
                "    def set_n_steps(self, n_steps):\n",
                "        self.n_steps = n_steps\n",
                "        self.delta_t = 1 / n_steps"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "T = make_net(n_inputs=DIM + 1, n_outputs=DIM, n_layers=3, n_hiddens=100).cuda()\n",
                "T = SDE(\n",
                "    T,\n",
                "    EPSILON,\n",
                "    N_STEPS,\n",
                ").cuda()\n",
                "\n",
                "D = make_net(n_inputs=DIM, n_outputs=1, n_layers=3, n_hiddens=100).cuda()\n",
                "\n",
                "T_opt = Adam(T.parameters(), lr=T_LR)\n",
                "D_opt = Adam(D.parameters(), lr=D_LR)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Ploter"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "@torch.no_grad()\n",
                "def map_dataset(SDE, X0: torch.Tensor, batch_size=32):\n",
                "    total_size = X0.shape[0]\n",
                "    mapped_data = []\n",
                "\n",
                "    for i in range(0, total_size, batch_size):\n",
                "        x0 = X0[i : i + batch_size]\n",
                "        xN = sde_push(SDE, x0, return_type=\"XN\")\n",
                "        mapped_data.append(xN)\n",
                "\n",
                "    if X0.shape[0] % batch_size != 0:\n",
                "        last_batch_size = X0.shape[0] % batch_size\n",
                "        last_x0 = X0[-last_batch_size:]\n",
                "        last_xN = sde_push(SDE, last_x0, return_type=\"XN\")\n",
                "        mapped_data.append(last_xN)\n",
                "\n",
                "    mapped_data = torch.cat(mapped_data)\n",
                "\n",
                "    return mapped_data\n",
                "\n",
                "\n",
                "def plot_results(source_dataset, target_dataset, mapped_dataset):\n",
                "    fig = plt.figure(figsize=(1.5 * 3, 1.5 * 1), dpi=150)\n",
                "\n",
                "    datasets = [source_dataset, target_dataset, mapped_dataset]\n",
                "    titles = [\"Input\", \"Target\", \"Trans\"]\n",
                "    for i, (dataset, title) in enumerate(zip(datasets, titles)):\n",
                "        dim = dataset.shape[-1]\n",
                "\n",
                "        x = dataset.numpy()[:, 0]\n",
                "        y = dataset.numpy()[:, 1]\n",
                "\n",
                "        angles = np.arctan2(y, x)\n",
                "        normalized_angles = (angles + np.pi) / (\n",
                "            2 * np.pi\n",
                "        )  # Normalize angles between 0 and 1\n",
                "        # Apply a smooth transition function for colors\n",
                "        colors = 0.5 * (1 + np.sin(2 * np.pi * normalized_angles - np.pi / 2))\n",
                "\n",
                "        if dim == 2:\n",
                "            ax = fig.add_subplot(1, 3, i + 1)\n",
                "            ax.scatter(\n",
                "                x,\n",
                "                y,\n",
                "                c=colors,  # Apply smooth color transition\n",
                "                cmap=\"rainbow\",  # Use rainbow colormap\n",
                "                s=1,  # Point size\n",
                "                edgecolors=\"none\",  # Remove point borders\n",
                "            )\n",
                "        if dim == 3:\n",
                "            z = dataset.numpy()[:, 2]\n",
                "            ax = fig.add_subplot(1, 3, i + 1, projection=\"3d\")\n",
                "            ax.scatter(\n",
                "                x,\n",
                "                y,\n",
                "                z,\n",
                "                c=colors,  # Apply smooth color transition\n",
                "                cmap=\"rainbow\",  # Use rainbow colormap\n",
                "                s=1,  # Point size\n",
                "                edgecolors=\"none\",  # Remove point borders\n",
                "            )\n",
                "        ax.set_title(title)\n",
                "        ax.grid()\n",
                "        ax.set_axis_off()\n",
                "        # axes[i].set_xlim([-2.5, 2.5])\n",
                "        # axes[i].set_ylim([-2.5, 2.5])\n",
                "\n",
                "    fig.tight_layout()\n",
                "\n",
                "    return fig, fig.axes"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Main training cycle"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "progress_bar = tqdm(total=MAX_STEPS)\n",
                "CONTINUE = 0\n",
                "\n",
                "for step in range(MAX_STEPS):\n",
                "    unfreeze(T)\n",
                "    freeze(D)\n",
                "\n",
                "    for t_iter in range(T_ITERS):\n",
                "        T_opt.zero_grad()\n",
                "        X0, X1 = X_sampler.sample(BATCH_SIZE), Y_sampler.sample(BATCH_SIZE)\n",
                "\n",
                "        trajectory, times, shifts = T(X0)\n",
                "        XN = trajectory[:, -1, :]\n",
                "        norm = torch.norm(shifts, p=2, dim=-1) ** 2\n",
                "        integral = INTEGRAL_SCALE * integrate(norm, times)\n",
                "        T_loss = (integral + D(X1) - D(XN)).mean()\n",
                "        writer.add_scalar(\"T_loss\", T_loss.item(), step)\n",
                "        T_loss.backward()\n",
                "        T_gradient_norm = torch.nn.utils.clip_grad_norm_(\n",
                "            T.parameters(), max_norm=T_GRADIENT_MAX_NORM\n",
                "        )\n",
                "        T_opt.step()\n",
                "\n",
                "    freeze(T)\n",
                "    unfreeze(D)\n",
                "\n",
                "    D_opt.zero_grad()\n",
                "    X0, X1 = X_sampler.sample(BATCH_SIZE), Y_sampler.sample(BATCH_SIZE)\n",
                "    trajectory, times, shifts = T(X0)\n",
                "    XN = trajectory[:, -1, :]\n",
                "    norm = torch.norm(shifts.flatten(start_dim=2), p=2, dim=-1) ** 2\n",
                "    integral = INTEGRAL_SCALE * integrate(norm, times)\n",
                "\n",
                "    D_loss = (-integral - D(X1) + D(XN)).mean()\n",
                "    writer.add_scalar(\"D_loss\", D_loss.item(), step)\n",
                "    D_loss.backward()\n",
                "    D_gradient_norm = torch.nn.utils.clip_grad_norm_(\n",
                "        D.parameters(), max_norm=D_GRADIENT_MAX_NORM\n",
                "    )\n",
                "    D_opt.step()\n",
                "\n",
                "    CONTINUE = step + 1\n",
                "    progress_bar.update(1)\n",
                "\n",
                "    if step % LOG_INTERVAL == 0:\n",
                "        progress_bar.close()\n",
                "        clear_output(wait=True)\n",
                "        progress_bar = tqdm(total=MAX_STEPS, initial=CONTINUE)\n",
                "        print(\"Plotting\")\n",
                "\n",
                "        original_dataset = torch.cat(\n",
                "            [\n",
                "                X_sampler.sample(BATCH_SIZE)\n",
                "                for i in range(PLOT_N_POINTS // BATCH_SIZE + 1)\n",
                "            ],\n",
                "            dim=0,\n",
                "        )[:PLOT_N_POINTS]\n",
                "\n",
                "        transfered_dataset = map_dataset(T, original_dataset, BATCH_SIZE).cpu()\n",
                "        original_dataset = original_dataset.cpu()\n",
                "        target_dataset = torch.cat(\n",
                "            [\n",
                "                Y_sampler.sample(BATCH_SIZE)\n",
                "                for i in range(PLOT_N_POINTS // BATCH_SIZE + 1)\n",
                "            ],\n",
                "            dim=0,\n",
                "        )[:PLOT_N_POINTS].cpu()\n",
                "\n",
                "        fig, axes = plot_results(original_dataset, target_dataset, transfered_dataset)\n",
                "        writer.add_image(\"trans\", fig2tensor(fig), step)\n",
                "        plt.show()\n",
                "        plt.close()\n",
                "        print(\"Computing L1 MSE\")\n",
                "        l1 = torch.nn.functional.l1_loss(target_dataset, transfered_dataset)\n",
                "        mse = torch.nn.functional.mse_loss(target_dataset, transfered_dataset)\n",
                "        writer.add_scalar(\"Metrics/L1\", l1, step)\n",
                "        writer.add_scalar(\"Metrics/MSE\", mse, step)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}