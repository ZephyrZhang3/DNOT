{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Imports\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import gc\n",
                "import json\n",
                "import warnings\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torchvision.datasets as datasets\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from tensorboardX import SummaryWriter\n",
                "from torchvision.transforms import Compose, ToTensor, Resize, Normalize, Lambda\n",
                "from PIL import PngImagePlugin\n",
                "\n",
                "from tqdm.auto import tqdm\n",
                "from IPython.display import clear_output\n",
                "\n",
                "sys.path.append(\"..\")\n",
                "from src.enot import SDE, integrate\n",
                "from src.resnet2 import ResNet_D\n",
                "from src.cunet import CUNet\n",
                "\n",
                "from src.tools import set_random_seed, unfreeze, freeze, weights_init_D, fig2tensor\n",
                "from src.mnistm_utils import MNISTM\n",
                "from src.plotters import (\n",
                "    plot_sde_pushed_images,\n",
                "    plot_sde_pushed_random_class_images,\n",
                ")\n",
                "from src.samplers import (\n",
                "    SubsetGuidedSampler,\n",
                "    SubsetGuidedDataset,\n",
                "    get_indicies_subset,\n",
                ")\n",
                "\n",
                "LARGE_ENOUGH_NUMBER = 100\n",
                "PngImagePlugin.MAX_TEXT_CHUNK = LARGE_ENOUGH_NUMBER * (1024**2)\n",
                "\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "\n",
                "%matplotlib inline "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gc.collect()\n",
                "torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Config\n",
                "\n",
                "Dataset choosing in the first rows\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "parameters"
                ]
            },
            "outputs": [],
            "source": [
                "SEED = 0x3060\n",
                "set_random_seed(SEED)\n",
                "\n",
                "# dataset choosing\n",
                "DATASET, DATASET_PATH = \"fmnist2mnist\", \"../datasets/\"\n",
                "# DATASET, DATASET_PATH = \"mnist2mnistm\", \"../datasets/\"\n",
                "# DATASET, DATASET_PATH = \"mnist2usps\", \"../datasets/\"\n",
                "# DATASET, DATASET_PATH = \"mnist2kmnist\", \"../datasets/\"\n",
                "\n",
                "IMG_SIZE = 32\n",
                "DATASET1_CHANNELS = 1\n",
                "DATASET2_CHANNELS = 1\n",
                "\n",
                "# GPU choosing\n",
                "DEVICE_IDS = [0]\n",
                "assert torch.cuda.is_available()\n",
                "\n",
                "CONTINUE = 0\n",
                "\n",
                "# All hyperparameters below is set to the values used for the experiments, which discribed in the article\n",
                "\n",
                "# training algorithm settings\n",
                "BATCH_SIZE = 32\n",
                "SUBSET_SIZE = 2\n",
                "NUM_LABELED = 10  # num of labeled target in training set\n",
                "\n",
                "T_ITERS = 10\n",
                "MAX_STEPS = 2500 + 1  # 2501 for testing\n",
                "INTEGRAL_SCALE = 1 / (3 * IMG_SIZE * IMG_SIZE)\n",
                "EPSILON_SCHEDULER_LAST_ITER = 20000\n",
                "\n",
                "# optimizer settings\n",
                "D_LR, T_LR = 1e-4, 1e-4\n",
                "BETA_D, BETA_T = 0.9, 0.9\n",
                "T_GRADIENT_MAX_NORM = float(500)\n",
                "D_GRADIENT_MAX_NORM = float(500)\n",
                "\n",
                "# SDE network settings\n",
                "EPSILON = 0  # [0 , 1, 10]\n",
                "IMAGE_INPUT = True\n",
                "PREDICT_SHIFT = True\n",
                "N_STEPS = 5  #\n",
                "UNET_BASE_FACTOR = 128\n",
                "TIME_DIM = 128\n",
                "USE_POSITIONAL_ENCODING = True\n",
                "ONE_STEP_INIT_ITERS = 0\n",
                "USE_GRADIENT_CHECKPOINT = False\n",
                "N_LAST_STEPS_WITHOUT_NOISE = 1\n",
                "\n",
                "# plot settings\n",
                "GRAY_PLOTS = True\n",
                "STEPS_TO_SHOW = 10\n",
                "\n",
                "# log settings\n",
                "SMART_INTERVALS = False\n",
                "INTERVAL_SHRINK_START_TIME = 0.98\n",
                "TRACK_VAR_INTERVAL = 100\n",
                "PLOT_INTERVAL = 500\n",
                "CPKT_INTERVAL = 500\n",
                "\n",
                "FID_EPOCHS = 1\n",
                "\n",
                "EXP_NAME = f\"ENOT_Class_{DATASET}_{SEED}\"\n",
                "OUTPUT_PATH = f\"../saved_models/{EXP_NAME}/\"\n",
                "\n",
                "if not os.path.exists(OUTPUT_PATH):\n",
                "    os.makedirs(OUTPUT_PATH)\n",
                "\n",
                "writer = SummaryWriter(f\"../logdir/{EXP_NAME}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "source_subset = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
                "new_labels_source = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\n",
                "target_subset = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
                "new_labels_target = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config = dict(\n",
                "    SEED=SEED,\n",
                "    DATASET=DATASET,\n",
                "    T_ITERS=T_ITERS,\n",
                "    D_LR=D_LR,\n",
                "    T_LR=T_LR,\n",
                "    BATCH_SIZE=BATCH_SIZE,\n",
                "    SUBSET_SIZE=SUBSET_SIZE,\n",
                "    UNET_BASE_FACTOR=UNET_BASE_FACTOR,\n",
                "    N_STEPS=N_STEPS,\n",
                "    EPSILON=EPSILON,\n",
                "    USE_POSITIONAL_ENCODING=USE_POSITIONAL_ENCODING,\n",
                "    TIME_DIM=TIME_DIM,\n",
                "    INTEGRAL_SCALE=INTEGRAL_SCALE,\n",
                "    ONE_STEP_INIT_ITERS=ONE_STEP_INIT_ITERS,\n",
                "    T_GRADIENT_MAX_NORM=T_GRADIENT_MAX_NORM,\n",
                "    D_GRADIENT_MAX_NORM=D_GRADIENT_MAX_NORM,\n",
                "    PREDICT_SHIFT=PREDICT_SHIFT,\n",
                "    SMART_INTERVALS=SMART_INTERVALS,\n",
                "    INTERVAL_SHRINK_START_TIME=INTERVAL_SHRINK_START_TIME,\n",
                "    USE_GRADIENT_CHECKPOINT=USE_GRADIENT_CHECKPOINT,\n",
                "    N_LAST_STEPS_WITHOUT_NOISE=N_LAST_STEPS_WITHOUT_NOISE,\n",
                "    TRACK_VAR_INTERVAL=TRACK_VAR_INTERVAL,\n",
                "    EPSILON_SCHEDULER_LAST_ITER=EPSILON_SCHEDULER_LAST_ITER,\n",
                "    FID_EPOCHS=FID_EPOCHS,\n",
                ")\n",
                "\n",
                "with open(os.path.join(OUTPUT_PATH, \"config.json\"), \"w\") as json_file:\n",
                "    json_str = json.dumps(config, indent=4)\n",
                "    json_file.write(json_str)\n",
                "\n",
                "log = dict(CONTINUE=CONTINUE)\n",
                "with open(os.path.join(OUTPUT_PATH, \"log.json\"), \"w\") as log_file:\n",
                "    log_str = json.dumps(log, indent=4)\n",
                "    log_file.write(log_str)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Initialize samplers\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "source_transform = Compose(\n",
                "    [\n",
                "        Resize((IMG_SIZE, IMG_SIZE)),\n",
                "        ToTensor(),\n",
                "        Normalize((0.5), (0.5)),\n",
                "    ]\n",
                ")\n",
                "target_transform = source_transform\n",
                "\n",
                "if DATASET == \"mnist2kmnist\":\n",
                "    source = datasets.MNIST\n",
                "    target = datasets.KMNIST\n",
                "\n",
                "elif DATASET == \"fmnist2mnist\":\n",
                "    source = datasets.FashionMNIST\n",
                "    target = datasets.MNIST\n",
                "\n",
                "elif DATASET == \"mnist2usps\":\n",
                "    source = datasets.MNIST\n",
                "    target = datasets.USPS\n",
                "\n",
                "elif DATASET == \"mnist2mnistm\":\n",
                "    DATASET1_CHANNELS = 3\n",
                "    DATASET2_CHANNELS = 3\n",
                "    GRAY_PLOTS = False\n",
                "    source = datasets.MNIST\n",
                "    target = MNISTM\n",
                "    source_transform = Compose(\n",
                "        [\n",
                "            Resize((IMG_SIZE, IMG_SIZE)),\n",
                "            ToTensor(),\n",
                "            Normalize((0.5), (0.5)),\n",
                "            Lambda(lambda x: -x.repeat(3, 1, 1)),\n",
                "        ]\n",
                "    )\n",
                "    target_transform = Compose(\n",
                "        [Resize(IMG_SIZE), ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "source_train = source(\n",
                "    root=DATASET_PATH, train=True, download=True, transform=source_transform\n",
                ")\n",
                "\n",
                "subset_samples, labels, source_class_indicies = get_indicies_subset(\n",
                "    source_train,\n",
                "    new_labels=new_labels_source,\n",
                "    classes=len(source_subset),\n",
                "    subset_classes=source_subset,\n",
                ")\n",
                "source_train = torch.utils.data.TensorDataset(\n",
                "    torch.stack(subset_samples), torch.LongTensor(labels)\n",
                ")\n",
                "\n",
                "\n",
                "target_train = target(\n",
                "    root=DATASET_PATH, train=True, download=True, transform=target_transform\n",
                ")\n",
                "\n",
                "target_subset_samples, target_labels, target_class_indicies = get_indicies_subset(\n",
                "    target_train,\n",
                "    new_labels=new_labels_target,\n",
                "    classes=len(target_subset),\n",
                "    subset_classes=target_subset,\n",
                ")\n",
                "target_train = torch.utils.data.TensorDataset(\n",
                "    torch.stack(target_subset_samples), torch.LongTensor(target_labels)\n",
                ")\n",
                "\n",
                "train_set = SubsetGuidedDataset(\n",
                "    source_train,\n",
                "    target_train,\n",
                "    num_labeled=NUM_LABELED,\n",
                "    in_indicies=source_class_indicies,\n",
                "    out_indicies=target_class_indicies,\n",
                ")\n",
                "\n",
                "full_set = SubsetGuidedDataset(\n",
                "    source_train,\n",
                "    target_train,\n",
                "    num_labeled=\"all\",\n",
                "    in_indicies=source_class_indicies,\n",
                "    out_indicies=target_class_indicies,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "T_XY_sampler = SubsetGuidedSampler(train_set, subsetsize=SUBSET_SIZE)\n",
                "D_XY_sampler = SubsetGuidedSampler(full_set, subsetsize=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "torch.cuda.empty_cache()\n",
                "gc.collect()\n",
                "clear_output()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Models initialization\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "D = ResNet_D(IMG_SIZE, nc=DATASET2_CHANNELS).cuda()\n",
                "D.apply(weights_init_D)\n",
                "\n",
                "T = CUNet(\n",
                "    DATASET1_CHANNELS, DATASET2_CHANNELS, TIME_DIM, base_factor=UNET_BASE_FACTOR\n",
                ").cuda()\n",
                "\n",
                "T = SDE(\n",
                "    shift_model=T,\n",
                "    epsilon=EPSILON,\n",
                "    n_steps=N_STEPS,\n",
                "    time_dim=TIME_DIM,\n",
                "    n_last_steps_without_noise=N_LAST_STEPS_WITHOUT_NOISE,\n",
                "    use_positional_encoding=USE_POSITIONAL_ENCODING,\n",
                "    use_gradient_checkpoint=USE_GRADIENT_CHECKPOINT,\n",
                "    predict_shift=PREDICT_SHIFT,\n",
                "    image_input=IMAGE_INPUT,\n",
                ").cuda()\n",
                "\n",
                "if len(DEVICE_IDS) > 1 and CONTINUE == 0:\n",
                "    T = nn.DataParallel(T, device_ids=DEVICE_IDS)\n",
                "    D = nn.DataParallel(D, device_ids=DEVICE_IDS)\n",
                "\n",
                "print(\"T params:\", np.sum([np.prod(p.shape) for p in T.parameters()]))\n",
                "print(\"D params:\", np.sum([np.prod(p.shape) for p in D.parameters()]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "T_opt = torch.optim.Adam(\n",
                "    T.parameters(), lr=T_LR, weight_decay=1e-10, betas=(BETA_T, 0.999)\n",
                ")\n",
                "D_opt = torch.optim.Adam(\n",
                "    D.parameters(), lr=D_LR, weight_decay=1e-10, betas=(BETA_D, 0.999)\n",
                ")\n",
                "T_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
                "    T_opt, milestones=[15000, 25000, 40000, 55000, 70000], gamma=0.5\n",
                ")\n",
                "D_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
                "    D_opt, milestones=[15000, 25000, 40000, 55000, 70000], gamma=0.5\n",
                ")\n",
                "\n",
                "if CONTINUE > 0:\n",
                "    T_opt.load_state_dict(\n",
                "        torch.load(os.path.join(OUTPUT_PATH, f\"T_opt_{SEED}_{CONTINUE}.pt\"))\n",
                "    )\n",
                "    T_scheduler.load_state_dict(\n",
                "        torch.load(os.path.join(OUTPUT_PATH, f\"T_scheduler_{SEED}_{CONTINUE}.pt\"))\n",
                "    )\n",
                "\n",
                "    T.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f\"T_{SEED}_{CONTINUE}.pt\")))\n",
                "    D.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f\"D_{SEED}_{CONTINUE}.pt\")))\n",
                "\n",
                "    if len(DEVICE_IDS) > 1:\n",
                "        T = nn.DataParallel(T, device_ids=DEVICE_IDS)\n",
                "        D = nn.DataParallel(D, device_ids=DEVICE_IDS)\n",
                "\n",
                "    D_opt.load_state_dict(\n",
                "        torch.load(os.path.join(OUTPUT_PATH, f\"D_opt_{SEED}_{CONTINUE}.pt\"))\n",
                "    )\n",
                "    D_scheduler.load_state_dict(\n",
                "        torch.load(os.path.join(OUTPUT_PATH, f\"D_scheduler_{SEED}_{CONTINUE}.pt\"))\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Plots Test\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_fixed, Y_fixed = D_XY_sampler.sample(NUM_LABELED)\n",
                "X_fixed, Y_fixed = X_fixed.flatten(0, 1), Y_fixed.flatten(0, 1)\n",
                "print(f\"[Debug] {X_fixed.shape=}\\n{Y_fixed.shape=}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plot_sde_pushed_images(X_fixed, Y_fixed, T, gray=GRAY_PLOTS)\n",
                "writer.add_image(\"class images[sde]\", fig2tensor(fig))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plot_sde_pushed_random_class_images(D_XY_sampler, T, gray=GRAY_PLOTS)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Main training cycle and logging\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gc.collect()\n",
                "torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def epsilon_scheduler(step):\n",
                "    return min(EPSILON, EPSILON * (step / EPSILON_SCHEDULER_LAST_ITER))\n",
                "\n",
                "\n",
                "progress_bar = tqdm(total=MAX_STEPS, initial=CONTINUE)\n",
                "\n",
                "\n",
                "for step in range(MAX_STEPS):\n",
                "    if step < CONTINUE:\n",
                "        continue\n",
                "\n",
                "    unfreeze(T)\n",
                "    freeze(D)\n",
                "\n",
                "    new_epsilon = epsilon_scheduler(step)\n",
                "    if len(DEVICE_IDS) > 1:\n",
                "        T.module.set_epsilon(new_epsilon)\n",
                "    else:\n",
                "        T.set_epsilon(new_epsilon)\n",
                "    # wandb.log({f\"Epsilon\": new_epsilon}, step=step)\n",
                "\n",
                "    for t_iter in range(T_ITERS):\n",
                "        T_opt.zero_grad()\n",
                "\n",
                "        X0, X1 = T_XY_sampler.sample(BATCH_SIZE)\n",
                "        # X0.requires_grad_()\n",
                "        X0 = X0.flatten(0, 1)\n",
                "        X1 = X1.flatten(0, 1)\n",
                "\n",
                "        trajectory, times, shifts = T(X0)\n",
                "        XN = trajectory[:, -1]\n",
                "        norm = torch.norm(shifts.flatten(start_dim=2), p=2, dim=-1) ** 2\n",
                "        integral = INTEGRAL_SCALE * integrate(norm, times[0])\n",
                "\n",
                "        T_loss = (integral + D(X1) - D(XN)).mean()\n",
                "        writer.add_scalar(\"T_loss\", T_loss.item(), step)\n",
                "        T_loss.backward()\n",
                "        T_gradient_norm = torch.nn.utils.clip_grad_norm_(\n",
                "            T.parameters(), max_norm=T_GRADIENT_MAX_NORM\n",
                "        )\n",
                "        T_opt.step()\n",
                "\n",
                "    # wandb.log({f\"T gradient norm\": T_gradient_norm.item()}, step=step)\n",
                "    # wandb.log({f\"Mean norm\": torch.sqrt(norm).mean().item()}, step=step)\n",
                "    # wandb.log({f\"T_loss\": T_loss.item()}, step=step)\n",
                "\n",
                "    T_scheduler.step()\n",
                "    del T_loss, X0, X1, XN\n",
                "    gc.collect()\n",
                "    torch.cuda.empty_cache()\n",
                "\n",
                "    freeze(T)\n",
                "    unfreeze(D)\n",
                "\n",
                "    D_opt.zero_grad()\n",
                "\n",
                "    # sample unlabeled Y~Q, X~P\n",
                "    X0, _ = T_XY_sampler.sample(BATCH_SIZE)\n",
                "    _, X1 = D_XY_sampler.sample(BATCH_SIZE * SUBSET_SIZE)\n",
                "    X0 = X0.flatten(0, 1)\n",
                "    X1 = X1.flatten(0, 1)\n",
                "\n",
                "    with torch.no_grad():\n",
                "        trajectory, times, shifts = T(X0)\n",
                "        XN = trajectory[:, -1]\n",
                "\n",
                "    norm = torch.norm(shifts.flatten(start_dim=2), p=2, dim=-1) ** 2\n",
                "    integral = INTEGRAL_SCALE * integrate(norm, times[0])\n",
                "    D_loss = (-integral - D(X1) + D(XN)).mean()\n",
                "    writer.add_scalar(\"D_loss\", D_loss.item(), step)\n",
                "    D_loss.backward()\n",
                "    D_gradient_norm = torch.nn.utils.clip_grad_norm_(\n",
                "        D.parameters(), max_norm=D_GRADIENT_MAX_NORM\n",
                "    )\n",
                "    D_opt.step()\n",
                "    D_scheduler.step()\n",
                "\n",
                "    # wandb.log({f\"D gradient norm\": D_gradient_norm.item()}, step=step)\n",
                "    # wandb.log({f\"D_loss\": D_loss.item()}, step=step)\n",
                "\n",
                "    # wandb.log({f\"integral\": integral.mean().item()}, step=step)\n",
                "    # wandb.log({f\"D_X1\": D_X1.mean().item()}, step=step)\n",
                "    # wandb.log({f\"D_XN\": D_XN.mean().item()}, step=step)\n",
                "    del D_loss, X0, X1, XN\n",
                "    gc.collect()\n",
                "    torch.cuda.empty_cache()\n",
                "\n",
                "    CONTINUE += 1\n",
                "    progress_bar.update(1)\n",
                "\n",
                "    if step % PLOT_INTERVAL == 0:\n",
                "        clear_output(wait=True)\n",
                "        progress_bar.close()\n",
                "        progress_bar = tqdm(total=MAX_STEPS, initial=CONTINUE)\n",
                "        print(\"Plotting\")\n",
                "\n",
                "        inference_T = T\n",
                "        inference_T.eval()\n",
                "        print(\"Fixed test Images\")\n",
                "        fig, axes = plot_sde_pushed_images(\n",
                "            X_fixed, Y_fixed, inference_T, gray=GRAY_PLOTS, plot_trajectory=False\n",
                "        )\n",
                "        writer.add_image(\"Fixed Test Images\", fig2tensor(fig), step)\n",
                "        plt.show(fig)\n",
                "        plt.close(fig)\n",
                "\n",
                "        print(\"Random test Images\")\n",
                "        fig, axes = plot_sde_pushed_random_class_images(\n",
                "            D_XY_sampler, inference_T, gray=GRAY_PLOTS, plot_trajectory=False\n",
                "        )\n",
                "        writer.add_image(\"Random Test Images\", fig2tensor(fig), step)\n",
                "        plt.show(fig)\n",
                "        plt.close(fig)\n",
                "\n",
                "    if step != 0 and step % CPKT_INTERVAL == 0:\n",
                "        inference_T = T\n",
                "\n",
                "        inference_T.eval()\n",
                "        freeze(T)\n",
                "        if len(DEVICE_IDS) > 1:\n",
                "            torch.save(\n",
                "                T.module.state_dict(), os.path.join(OUTPUT_PATH, f\"T_{SEED}_{step}.pt\")\n",
                "            )\n",
                "            torch.save(\n",
                "                D.module.state_dict(), os.path.join(OUTPUT_PATH, f\"D_{SEED}_{step}.pt\")\n",
                "            )\n",
                "        else:\n",
                "            torch.save(T.state_dict(), os.path.join(OUTPUT_PATH, f\"T_{SEED}_{step}.pt\"))\n",
                "            torch.save(D.state_dict(), os.path.join(OUTPUT_PATH, f\"D_{SEED}_{step}.pt\"))\n",
                "\n",
                "        torch.save(\n",
                "            D_opt.state_dict(), os.path.join(OUTPUT_PATH, f\"D_opt_{SEED}_{step}.pt\")\n",
                "        )\n",
                "        torch.save(\n",
                "            T_opt.state_dict(), os.path.join(OUTPUT_PATH, f\"T_opt_{SEED}_{step}.pt\")\n",
                "        )\n",
                "        torch.save(\n",
                "            D_scheduler.state_dict(),\n",
                "            os.path.join(OUTPUT_PATH, f\"D_scheduler_{SEED}_{step}.pt\"),\n",
                "        )\n",
                "        torch.save(\n",
                "            T_scheduler.state_dict(),\n",
                "            os.path.join(OUTPUT_PATH, f\"T_scheduler_{SEED}_{step}.pt\"),\n",
                "        )\n",
                "\n",
                "        log[\"CONTINUE\"] = CONTINUE\n",
                "        with open(os.path.join(OUTPUT_PATH, \"log.json\"), \"w\") as log_file:\n",
                "            log_str = json.dumps(log, indent=4)\n",
                "            log_file.write(log_str)\n",
                "    if step % TRACK_VAR_INTERVAL == 0:\n",
                "        # after training, using test_transport.ipynb to get fid acc ...\n",
                "        pass\n",
                "\n",
                "    gc.collect()\n",
                "    torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    writer.close()\n",
                "    progress_bar.close()\n",
                "except Exception:\n",
                "    pass"
            ]
        }
    ],
    "metadata": {
        "celltoolbar": "Tags",
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
